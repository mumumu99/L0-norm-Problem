{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L0-norm.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kgARKE4-FRfG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mumumu99/L0-norm-Problem/blob/main/L0_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Ml3dP4FRe8",
        "outputId": "dfbeb130-45d7-4af0-f7af-96cb6461797c"
      },
      "source": [
        "!pip install wget\n",
        "import wget, pickle, os\n",
        "\n",
        "def load_data():\n",
        "    # Load dataset from DIYA GitLab\n",
        "    url = \"https://gitlab.diyaml.com/moong1234/application/raw/release/data.pkl\"\n",
        "    if not os.path.isfile(\"data.pkl\"):\n",
        "        wget.download(url, 'data.pkl')\n",
        "    \n",
        "    path = \"data.pkl\"\n",
        "    with open(path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "data, label = load_data()\n",
        "print(data.shape, label.shape)\n",
        "data, label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=2e999de566fad2c2af0097e8e259b0c90686f96dee29b11451b227d2689af4dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "(4096, 12) (4096, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.,  1.,  1., ...,  1., -1.,  1.],\n",
              "        [ 1., -1., -1., ..., -1.,  1.,  1.],\n",
              "        [-1.,  1.,  1., ..., -1., -1., -1.],\n",
              "        ...,\n",
              "        [ 1., -1.,  1., ...,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1., ..., -1., -1.,  1.],\n",
              "        [-1.,  1., -1., ...,  1.,  1., -1.]]), array([[0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVl4xmQgFRe-"
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "ratio = [.6, .2, .2]\n",
        "\n",
        "train_data_x = data[:int(data.shape[0]*ratio[0]), :]\n",
        "test_data_x = data[int(data.shape[0]*ratio[0]):int(data.shape[0]*(1-ratio[1])), :]\n",
        "validation_data_x = data[int(data.shape[0]*(1-ratio[1])):, :]\n",
        "\n",
        "train_data_y = label[:int(data.shape[0]*ratio[0]), :]\n",
        "test_data_y = label[int(data.shape[0]*ratio[0]):int(data.shape[0]*(1-ratio[1])), :]\n",
        "validation_data_y = label[int(data.shape[0]*(1-ratio[1])):, :]\n",
        "\n",
        "train_data_x = torch.tensor(train_data_x, dtype=torch.float64, device=device).double()\n",
        "train_data_y = torch.tensor(train_data_y, dtype=torch.float64, device=device).double()\n",
        "test_data_x = torch.tensor(test_data_x, dtype=torch.float64, device=device).double()\n",
        "test_data_y = torch.tensor(test_data_y, dtype=torch.float64, device=device).double()\n",
        "validation_data_x = torch.tensor(validation_data_x, dtype=torch.float64, device=device).double()\n",
        "validation_data_y = torch.tensor(validation_data_y, dtype=torch.float64, device=device).double()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFgzac_FFRfA"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "dataset = TensorDataset(train_data_x, train_data_y)\n",
        "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaBndDX_FRfB"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.l1 = torch.nn.Linear(input_dim, hidden_dim)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.l2 = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        y_pred = self.sigmoid(self.l2(out1))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "model = MLP(12, 20, 2)\n",
        "\n",
        "from torchsummary import summary as summary_\n",
        "summary_(model, (2457, 12), batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTPKdyLXGxkJ",
        "outputId": "3716bd1c-78c8-452f-c870-3acd8b05076d"
      },
      "source": [
        "criterion = torch.nn.BCELoss(reduction = 'mean')\r\n",
        "optimizer = optim.SGD(model.parameters(), lr = 5)\r\n",
        "\r\n",
        "for epoch in range(10001):\r\n",
        "    y_pred = model(train_data_x.float())\r\n",
        "    loss = criterion(y_pred, train_data_y.float())\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if epoch % 200 == 0:\r\n",
        "        print(f'Epoch : {epoch} / 10000 | Loss : {loss.item():.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 / 10000 | Loss : 0.7050\n",
            "Epoch : 200 / 10000 | Loss : 0.6918\n",
            "Epoch : 400 / 10000 | Loss : 0.6909\n",
            "Epoch : 600 / 10000 | Loss : 0.6876\n",
            "Epoch : 800 / 10000 | Loss : 0.6836\n",
            "Epoch : 1000 / 10000 | Loss : 0.6807\n",
            "Epoch : 1200 / 10000 | Loss : 0.6850\n",
            "Epoch : 1400 / 10000 | Loss : 0.6799\n",
            "Epoch : 1600 / 10000 | Loss : 0.6784\n",
            "Epoch : 1800 / 10000 | Loss : 0.6763\n",
            "Epoch : 2000 / 10000 | Loss : 0.6186\n",
            "Epoch : 2200 / 10000 | Loss : 0.4182\n",
            "Epoch : 2400 / 10000 | Loss : 0.2115\n",
            "Epoch : 2600 / 10000 | Loss : 0.1500\n",
            "Epoch : 2800 / 10000 | Loss : 0.1098\n",
            "Epoch : 3000 / 10000 | Loss : 0.0799\n",
            "Epoch : 3200 / 10000 | Loss : 0.0631\n",
            "Epoch : 3400 / 10000 | Loss : 0.0521\n",
            "Epoch : 3600 / 10000 | Loss : 0.0441\n",
            "Epoch : 3800 / 10000 | Loss : 0.0378\n",
            "Epoch : 4000 / 10000 | Loss : 0.0327\n",
            "Epoch : 4200 / 10000 | Loss : 0.0286\n",
            "Epoch : 4400 / 10000 | Loss : 0.0252\n",
            "Epoch : 4600 / 10000 | Loss : 0.0224\n",
            "Epoch : 4800 / 10000 | Loss : 0.0202\n",
            "Epoch : 5000 / 10000 | Loss : 0.0183\n",
            "Epoch : 5200 / 10000 | Loss : 0.0167\n",
            "Epoch : 5400 / 10000 | Loss : 0.0154\n",
            "Epoch : 5600 / 10000 | Loss : 0.0142\n",
            "Epoch : 5800 / 10000 | Loss : 0.0133\n",
            "Epoch : 6000 / 10000 | Loss : 0.0124\n",
            "Epoch : 6200 / 10000 | Loss : 0.0117\n",
            "Epoch : 6400 / 10000 | Loss : 0.0110\n",
            "Epoch : 6600 / 10000 | Loss : 0.0105\n",
            "Epoch : 6800 / 10000 | Loss : 0.0100\n",
            "Epoch : 7000 / 10000 | Loss : 0.0095\n",
            "Epoch : 7200 / 10000 | Loss : 0.0092\n",
            "Epoch : 7400 / 10000 | Loss : 0.0088\n",
            "Epoch : 7600 / 10000 | Loss : 0.0085\n",
            "Epoch : 7800 / 10000 | Loss : 0.0082\n",
            "Epoch : 8000 / 10000 | Loss : 0.0079\n",
            "Epoch : 8200 / 10000 | Loss : 0.0077\n",
            "Epoch : 8400 / 10000 | Loss : 0.0075\n",
            "Epoch : 8600 / 10000 | Loss : 0.0073\n",
            "Epoch : 8800 / 10000 | Loss : 0.0071\n",
            "Epoch : 9000 / 10000 | Loss : 0.0069\n",
            "Epoch : 9200 / 10000 | Loss : 0.0067\n",
            "Epoch : 9400 / 10000 | Loss : 0.0066\n",
            "Epoch : 9600 / 10000 | Loss : 0.0064\n",
            "Epoch : 9800 / 10000 | Loss : 0.0063\n",
            "Epoch : 10000 / 10000 | Loss : 0.0062\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}